import os
import json
import random
import numpy as np
from sklearn.model_selection import train_test_split
from model import NeuroUXModel
from data_processor import DataProcessor

# === 1. GENERAR DATOS SINT√âTICOS DE ALTA CALIDAD ===
def generate_synthetic_data(num_samples=100):
    """Genera datos sint√©ticos con ratings altos (0.8‚Äì1.0)"""
    NAMES = [
        "TechFlow", "GreenRoots", "MindfulHR", "NovaLabs", "UrbanRide", "ArtisanCraft",
        "EduFuture", "ZenSpace", "CryptoTrust", "BloomKids", "SkylineBuild", "PulseHealth",
        "StyleHive", "DataShield", "TerraFarms", "SoundScape", "LegalEase", "GlowBeauty"
    ]
    
    MISSIONS = [
        "Innovaci√≥n {sector} para el futuro",
        "Soluciones {sector} con enfoque en {value1} y {value2}",
        "Transformar el {sector} mediante {value1}",
        "Experiencias {sector} dise√±adas para {audience}",
        "Impulsar el crecimiento de {audience} con {value1}"
    ]
    
    VALUES = [
        "innovaci√≥n", "tecnolog√≠a", "excelencia", "sostenibilidad", "calidad", "confianza",
        "creatividad", "eficiencia", "transparencia", "seguridad", "accesibilidad", "√©tica"
    ]
    
    SECTORS = [
        "tecnolog√≠a", "salud", "finanzas", "educaci√≥n", "moda", "alimentos", "medio ambiente",
        "fitness", "dise√±o", "recursos humanos", "ciencia", "movilidad", "arte", "m√∫sica"
    ]
    
    AUDIENCES = [
        "empresas B2B", "consumidores conscientes", "j√≥venes urbanos", "familias",
        "emprendedores", "instituciones acad√©micas", "clientes premium"
    ]

    synthetic = []
    for _ in range(num_samples):
        sector = random.choice(SECTORS)
        audience = random.choice(AUDIENCES)
        value1, value2 = random.sample(VALUES, 2)
        
        mission = random.choice(MISSIONS).format(
            sector=sector,
            audience=audience,
            value1=value1,
            value2=value2
        )
        
        values = ", ".join(random.sample(VALUES, random.randint(3, 5)))
        
        synthetic.append({
            "input": {
                "name": random.choice(NAMES),
                "mission": mission,
                "values": values,
                "sector": sector,
                "audience": audience
            },
            "rating": round(random.uniform(0.85, 1.0), 2),  # Rating alto
            "feedback": "excelente"
        })
    
    return synthetic

# === 2. CARGAR DATOS REALES ===
def load_real_data(data_path):
    """Carga datos reales: training + feedback + pending"""
    if not os.path.exists(data_path):
        return [], [], []
    
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    training = data.get('training_data', [])
    feedback = data.get('feedback_data', [])
    pending = data.get('pending_feedback', [])
    
    return training, feedback, pending

# === 3. ENTRENAMIENTO COMPLETO ===
def train_full_model():
    print("=" * 60)
    print("üß† NEURO UX STYLER - ENTRENAMIENTO COMPLETO")
    print("=" * 60)
    
    # Rutas
    data_path = 'data/combined_training_data.json'
    model_path = 'neuro_ux_model.keras'
    
    # Cargar datos reales
    training_data, feedback_data, pending_feedback = load_real_data(data_path)
    print(f"‚úÖ Datos reales cargados:")
    print(f"   - Training: {len(training_data)}")
    print(f"   - Feedback usados: {len(feedback_data)}")
    print(f"   - Feedback pendientes: {len(pending_feedback)}")
    
    # Generar datos sint√©ticos
    synthetic_data = generate_synthetic_data(num_samples=150)
    print(f"‚ú® Datos sint√©ticos generados: {len(synthetic_data)} (ratings altos)")
    
    # Combinar TODO
    all_data = training_data + feedback_data + pending_feedback + synthetic_data
    print(f"üìä Total de muestras para entrenamiento: {len(all_data)}")
    
    if len(all_data) < 20:
        print("‚ùå No hay suficientes datos. A√±ade m√°s ejemplos.")
        return
    
    # Preparar features
    processor = DataProcessor()
    X, y = [], []
    
    for item in all_data:
        try:
            features, _, _, _ = processor.encode_input(item['input'])
            X.append(features[0])
            y.append(item.get('rating', 0.5))
        except Exception as e:
            print(f"‚ö†Ô∏è Error al procesar item: {e}")
            continue
    
    X = np.array(X)
    y = np.array(y)
    print(f"‚úÖ Features preparados: {X.shape}")
    
    # Dividir
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Entrenar
    print("\nüöÄ Iniciando entrenamiento...")
    model = NeuroUXModel()
    history = model.train(X_train, y_train, X_val, y_val, epochs=120)
    metrics = model.evaluate(X_val, y_val)
    
    # Guardar
    model.save_model()
    
    print("\n" + "="*60)
    print("‚úÖ ENTRENAMIENTO COMPLETO FINALIZADO")
    print("="*60)
    print(f"üéØ Precisi√≥n: {metrics['accuracy']*100:.2f}%")
    print(f"üìâ P√©rdida: {metrics['loss']:.4f}")
    print(f"üìà AUC: {metrics.get('auc', 0.0):.4f}")
    print(f"üíæ Modelo guardado en: {model_path}")
    
    # Vaciar feedbacks pendientes (opcional)
    if os.path.exists(data_path):
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        data['pending_feedback'] = []
        with open(data_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print("üóëÔ∏è Feedbacks pendientes limpiados (listos para nuevos)")

if __name__ == "__main__":
    train_full_model()